[{"categories":null,"contents":"Este archivo existe únicamente para responder a la URL /search con la plantilla de diseño search relacionada.\nNo se muestra ningún contenido aquí, todo el contenido se basa en la plantilla layouts/page/search.html\nEstablecer una prioridad muy baja en el mapa del sitio le dirá a los motores de búsqueda que éste no es un contenido importante.\nEsta implementación utiliza Fusejs, jquery y mark.js\nConfiguración inicial La búsqueda depende del tipo de contenido de salida adicional de JSON en config.toml\n``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nBúsqueda de archivos adicionales Para buscar campos adicionales definidos en el front matter, debes añadirlo en 2 lugares.\nEditar layouts/_default/index.JSON Esto expone los valores en /index.json: por ejemplo, para agregar categories ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEditar las opciones de fuse.js para buscar static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://gilcrest.github.io/search/","summary":"Este archivo existe únicamente para responder a la URL /search con la plantilla de diseño search relacionada.\nNo se muestra ningún contenido aquí, todo el contenido se basa en la plantilla layouts/page/search.html\nEstablecer una prioridad muy baja en el mapa del sitio le dirá a los motores de búsqueda que éste no es un contenido importante.\nEsta implementación utiliza Fusejs, jquery y mark.js\nConfiguración inicial La búsqueda depende del tipo de contenido de salida adicional de JSON en config.","tags":null,"title":"Resultados de Búsqueda"},{"categories":null,"contents":"Este archivo existe únicamente para responder a la URL /search con la plantilla de diseño search relacionada.\nNo se muestra ningún contenido aquí, todo el contenido se basa en la plantilla layouts/page/search.html\nEstablecer una prioridad muy baja en el mapa del sitio le dirá a los motores de búsqueda que éste no es un contenido importante.\nEsta implementación utiliza Fusejs, jquery y mark.js\nConfiguración inicial La búsqueda depende del tipo de contenido de salida adicional de JSON en config.toml\n``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nBúsqueda de archivos adicionales Para buscar campos adicionales definidos en el front matter, debes añadirlo en 2 lugares.\nEditar layouts/_default/index.JSON Esto expone los valores en /index.json: por ejemplo, para agregar categories ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEditar las opciones de fuse.js para buscar static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://gilcrest.github.io/search/","summary":"Este archivo existe únicamente para responder a la URL /search con la plantilla de diseño search relacionada.\nNo se muestra ningún contenido aquí, todo el contenido se basa en la plantilla layouts/page/search.html\nEstablecer una prioridad muy baja en el mapa del sitio le dirá a los motores de búsqueda que éste no es un contenido importante.\nEsta implementación utiliza Fusejs, jquery y mark.js\nConfiguración inicial La búsqueda depende del tipo de contenido de salida adicional de JSON en config.","tags":null,"title":"Resultados de Búsqueda"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://gilcrest.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://gilcrest.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://gilcrest.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://gilcrest.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://gilcrest.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://gilcrest.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://gilcrest.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://gilcrest.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://gilcrest.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://gilcrest.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://gilcrest.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://gilcrest.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://gilcrest.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://gilcrest.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://gilcrest.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://gilcrest.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://gilcrest.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://gilcrest.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://gilcrest.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://gilcrest.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://gilcrest.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://gilcrest.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"অনুসন্ধানের ফলাফল"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://gilcrest.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"অনুসন্ধানের ফলাফল"},{"categories":null,"contents":"A few weeks ago, I gave a presentation to the Boston Go Meetup on Low-Dependency Database Migrations and Integration, in which I discuss how I handle database migrations and database integration in the go-api-basic project that I\u0026rsquo;ve been working on. In the presentation I mention several tools that I use, so I wanted to add links to them here.\n Mage PostgreSQL JetBrains DataGrip sqlc  The video for the talk is below:\n   ","date":"March 15, 2022","hero":"/images/default-hero.jpg","permalink":"https://gilcrest.github.io/posts/migrations/","summary":"A few weeks ago, I gave a presentation to the Boston Go Meetup on Low-Dependency Database Migrations and Integration, in which I discuss how I handle database migrations and database integration in the go-api-basic project that I\u0026rsquo;ve been working on. In the presentation I mention several tools that I use, so I wanted to add links to them here.\n Mage PostgreSQL JetBrains DataGrip sqlc  The video for the talk is below:","tags":null,"title":"Low-Dependency Database Migrations and Integration"},{"categories":null,"contents":"Thoughts on Logging I\u0026rsquo;ve gone through a few logging phases in my career. I logged everything. It was great, until the logs became meaningless because there were too many. I logged only errors, but in some cases that was not enough. Now I\u0026rsquo;m somewhere in the middle. I do believe in logging all errors and detailed how I do that in my last post. There are also times when it\u0026rsquo;s helpful to have some debugging logs in place. As an example, if you\u0026rsquo;ve ever tried to build a google doc using their APIs, then you may know that it can be helpful to have some tidbits of information about the document index position along your code/document path. In cases like this, I will leave debug logs in place in order to be able to pull the thread on them later if need be. Often times, I may deploy a change with some logs in place until I\u0026rsquo;ve seen enough data in action in production and then back out the logs in the next change when I\u0026rsquo;m satisfied. In general, I try to minimize the amount of logging in my code and only put logs in where it counts.\nLogging in go-api-basic with zerolog go-api-basic uses the zerolog library from Olivier Poitrey. I\u0026rsquo;m not gonna lie - initially, I chose this library because Olivier uses it at Netflix and that was enough for me. Over time though, I\u0026rsquo;ve really come to love this logging library and Olivier is a great maintainer. I spent a lot of time a couple of years ago helping with the README and a number of other things in the library along the way. I\u0026rsquo;ve learned a lot about Go and open source just from these interactions. If I use a library, I generally try to give back in some way to it, but often times through these interactions, I get back more in return, actually.\nThe mechanics for using zerolog are straightforward and are well documented in the library\u0026rsquo;s README. zerolog takes an io.Writer as input to create a new logger; for simplicity in go-api-basic, I use os.Stdout.\nSetting Logger State on Startup When starting go-api-basic, there are several flags which setup the logger:\n   Flag Name Description Environment Variable Default     log-level zerolog logging level (debug, info, etc.) LOG_LEVEL debug   log-level-min sets the minimum accepted logging level LOG_LEVEL_MIN debug   log-error-stack If true, log full error stacktrace, else just log error LOG_ERROR_STACK false      go-api-basic uses the ff library from Peter Bourgon, which allows for using either flags or environment variables. Click here if you want more info on this setup. Going forward, we\u0026rsquo;ll assume you\u0026rsquo;ve chosen flags.\n The log-level flag sets the Global logging level for your zerolog.Logger.\nzerolog allows for logging at the following levels (from highest to lowest):\n panic (zerolog.PanicLevel, 5) fatal (zerolog.FatalLevel, 4) error (zerolog.ErrorLevel, 3) warn (zerolog.WarnLevel, 2) info (zerolog.InfoLevel, 1) debug (zerolog.DebugLevel, 0) trace (zerolog.TraceLevel, -1)  The log-level-min flag sets the minimum accepted logging level, which means, for example, if you set the minimum level to error, the only logs that will be sent to your chosen output will be those that are greater than or equal to error (error, fatal and panic).\nThe log-error-stack boolean flag tells whether to log stack traces for each error. If true, the zerolog.ErrorStackMarshaler will be set to pkgerrors.MarshalStack which means, for errors raised using the github.com/pkg/errors package, the error stack trace will be captured and printed along with the log. All errors raised in go-api-basic are raised using github.com/pkg/errors.\nAfter parsing the command line flags, zerolog.Logger is initialized in main.go\n// setup logger with appropriate defaults lgr := logger.NewLogger(os.Stdout, minlvl, true) and subsequently injected into the app.Server struct as a Server parameter.\n// initialize server configuration parameters params := app.NewServerParams(lgr, serverDriver)  // initialize Server s, err := app.NewServer(mr, params) if err != nil {  lgr.Fatal().Err(err).Msg(\u0026#34;Error from app.NewServer\u0026#34;) } Logger Setup in Handlers The Server.routes method is responsible for registering routes and corresponding middleware/handlers to the Server\u0026rsquo;s gorilla/mux router. For each route registered to the handler, upon execution, the initialized zerolog.Logger struct is added to the request context through the Server.loggerChain method.\n// register routes/middleware/handlers to the Server router func (s *Server) routes() {   // Match only POST requests at /api/v1/movies  // with Content-Type header = application/json  s.router.Handle(moviesV1PathRoot,  s.loggerChain().Extend(s.ctxWithUserChain()).  Append(s.authorizeUserHandler).  Append(s.jsonContentTypeResponseHandler).  ThenFunc(s.handleMovieCreate)).  Methods(http.MethodPost).  Headers(contentTypeHeaderKey, appJSONContentTypeHeaderVal)  ... The Server.loggerChain method sets up the logger with pre-populated fields, including the request method, url, status, size, duration, remote IP, user agent, referer. A unique Request ID is also added to the logger, context and response headers.\nfunc (s *Server) loggerChain() alice.Chain {  ac := alice.New(hlog.NewHandler(s.logger),  hlog.AccessHandler(func(r *http.Request, status, size int, duration time.Duration) {  hlog.FromRequest(r).Info().  Str(\u0026#34;method\u0026#34;, r.Method).  Stringer(\u0026#34;url\u0026#34;, r.URL).  Int(\u0026#34;status\u0026#34;, status).  Int(\u0026#34;size\u0026#34;, size).  Dur(\u0026#34;duration\u0026#34;, duration).  Msg(\u0026#34;request logged\u0026#34;)  }),  hlog.RemoteAddrHandler(\u0026#34;remote_ip\u0026#34;),  hlog.UserAgentHandler(\u0026#34;user_agent\u0026#34;),  hlog.RefererHandler(\u0026#34;referer\u0026#34;),  hlog.RequestIDHandler(\u0026#34;request_id\u0026#34;, \u0026#34;Request-Id\u0026#34;),  )   return ac } For every request, you\u0026rsquo;ll get a request log that looks something like the following:\n{  \u0026#34;level\u0026#34;: \u0026#34;info\u0026#34;,  \u0026#34;remote_ip\u0026#34;: \u0026#34;127.0.0.1\u0026#34;,  \u0026#34;user_agent\u0026#34;: \u0026#34;PostmanRuntime/7.28.0\u0026#34;,  \u0026#34;request_id\u0026#34;: \u0026#34;c3npn8ea0brt0m3scvq0\u0026#34;,  \u0026#34;method\u0026#34;: \u0026#34;POST\u0026#34;,  \u0026#34;url\u0026#34;: \u0026#34;/api/v1/movies\u0026#34;,  \u0026#34;status\u0026#34;: 401,  \u0026#34;size\u0026#34;: 0,  \u0026#34;duration\u0026#34;: 392.254496,  \u0026#34;time\u0026#34;: 1626315682,  \u0026#34;severity\u0026#34;: \u0026#34;INFO\u0026#34;,  \u0026#34;message\u0026#34;: \u0026#34;request logged\u0026#34; } All error logs will have the same request metadata, including request_id. The Request-Id is also sent back as part of the error response as a response header, allowing you to link the two. An error log will look something like the following:\n{  \u0026#34;level\u0026#34;: \u0026#34;error\u0026#34;,  \u0026#34;remote_ip\u0026#34;: \u0026#34;127.0.0.1\u0026#34;,  \u0026#34;user_agent\u0026#34;: \u0026#34;PostmanRuntime/7.28.0\u0026#34;,  \u0026#34;request_id\u0026#34;: \u0026#34;c3nppj6a0brt1dho9e2g\u0026#34;,  \u0026#34;error\u0026#34;: \u0026#34;googleapi: Error 401: Request is missing required authentication credential. Expected OAuth 2 access token, login cookie or other valid authentication credential. See https://developers.google.com/identity/sign-in/web/devconsole-project., unauthorized\u0026#34;,  \u0026#34;http_statuscode\u0026#34;: 401,  \u0026#34;realm\u0026#34;: \u0026#34;go-api-basic\u0026#34;,  \u0026#34;time\u0026#34;: 1626315981,  \u0026#34;severity\u0026#34;: \u0026#34;ERROR\u0026#34;,  \u0026#34;message\u0026#34;: \u0026#34;Unauthenticated Request\u0026#34; }  The above error log demonstrates a log for an error with stack trace turned off.\n If the Logger is to be used beyond the scope of the handler, it should be pulled from the request context in the handler and sent as a parameter to any inner calls. The Logger is added only to the request context to capture request related fields with the Logger and be able to pass the initialized logger and middleware handlers easier to the app/route handler. Additional use of the logger should be directly called out in function/method signatures so there are no surprises. All logs from the logger passed down get the benefit of the request metadata though, which is great!\nReading and Modifying Logger State You can retrieve and update the state of these flags using the {{base_url}}/api/v1/logger endpoint.\nTo retrieve the current logger state use a GET request:\ncurl --location --request GET \u0026#39;http://127.0.0.1:8080/api/v1/logger\u0026#39; \\ --header \u0026#39;Authorization: Bearer \u0026lt;REPLACE WITH ACCESS TOKEN\u0026gt;\u0026#39; and the response will look something like:\n{  \u0026#34;logger_minimum_level\u0026#34;: \u0026#34;debug\u0026#34;,  \u0026#34;global_log_level\u0026#34;: \u0026#34;error\u0026#34;,  \u0026#34;log_error_stack\u0026#34;: false } In order to update the logger state use a PUT request:\ncurl --location --request PUT \u0026#39;http://127.0.0.1:8080/api/v1/logger\u0026#39; \\ --header \u0026#39;Content-Type: application/json\u0026#39; \\ --header \u0026#39;Authorization: Bearer \u0026lt;REPLACE WITH ACCESS TOKEN\u0026gt;\u0026#39; \\ --data-raw \u0026#39;{ \u0026#34;global_log_level\u0026#34;: \u0026#34;debug\u0026#34;, \u0026#34;log_error_stack\u0026#34;: \u0026#34;true\u0026#34; }\u0026#39; and the response will look something like:\n{  \u0026#34;logger_minimum_level\u0026#34;: \u0026#34;debug\u0026#34;,  \u0026#34;global_log_level\u0026#34;: \u0026#34;debug\u0026#34;,  \u0026#34;log_error_stack\u0026#34;: true } The PUT response is the same as the GET response, but with updated values. In the examples above, I used a scenario where the logger state started with the global logging level (global_log_level) at error and error stack tracing (log_error_stack) set to false. The PUT request then updates the logger state, setting the global logging level to debug and the error stack tracing. You might do something like this if you are debugging an issue and need to see debug logs or error stacks to help with that.\n #golang modules you probably shouldn\u0026#39;t usehttps://t.co/33ROwusCgx — basically superseded by 1.13+ stdlib package errors https://t.co/TC8K4IAw85, https://t.co/XRNj1H0zTJ — plain DI with interfaces/mocks is strictly superior almost always (exceptions know they\u0026#39;re exceptions)\n\u0026mdash; ✕✕✕✕✕ (@peterbourgon) July 3, 2021  Peter Bourgon recently tweeted the above about github.com/pkg/errors. He\u0026rsquo;s not wrong. In general the standard library is always the way to go. For years I only used the standard library for raising errors and would annotate each error with the function name in order to capture a pseudo stack trace exactly like Rob Pike does in this post (the errs.Op field). I believe in annotating and logging every error - not everyone does. It can cause noise in your logs, but in my experience, it\u0026rsquo;s helpful. After years of trying to annotate every error though, I found I made too many mistakes. I kept forgetting to log the function name or I would misspell it, etc. I switched to use github.com/pkg/errors because of it\u0026rsquo;s stack trace capability as well as the integration zerolog has with it. Stack trace for errors can certainly be overkill though, hence the ability to turn it on/off with a service for tactical usage can come in handy.\n No actual logs were harmed in this post.\n ","date":"July 13, 2021","hero":"/posts/logging/hero.jpg","permalink":"https://gilcrest.github.io/posts/logging/","summary":"Thoughts on Logging I\u0026rsquo;ve gone through a few logging phases in my career. I logged everything. It was great, until the logs became meaningless because there were too many. I logged only errors, but in some cases that was not enough. Now I\u0026rsquo;m somewhere in the middle. I do believe in logging all errors and detailed how I do that in my last post. There are also times when it\u0026rsquo;s helpful to have some debugging logs in place.","tags":null,"title":"Logging in go-api-basic"},{"categories":null,"contents":"Handling errors is really important in Go. Errors are first class citizens and there are many different approaches for handling them. Initially I started off basing my error handling almost entirely on a blog post from Rob Pike and created a carve-out from his code to meet my needs. It served me well for a long time, but found over time I wanted a way to easily get a stacktrace of the error, which led me to Dave Cheney\u0026rsquo;s https://github.com/pkg/errors package. I now use a combination of the two. The implementation below is sourced from my go-api-basic repo, indeed, this post will be folded into its README as well.\nRequirements My requirements for REST API error handling are the following:\n Requests for users who are not properly authenticated should return a 401 Unauthorized error with a WWW-Authenticate response header and an empty response body. Requests for users who are authenticated, but do not have permission to access the resource, should return a 403 Forbidden error with an empty response body. All requests which are due to a client error (invalid data, malformed JSON, etc.) should return a 400 Bad Request and a response body which looks similar to the following:  {  \u0026#34;error\u0026#34;: {  \u0026#34;kind\u0026#34;: \u0026#34;input_validation_error\u0026#34;,  \u0026#34;param\u0026#34;: \u0026#34;director\u0026#34;,  \u0026#34;message\u0026#34;: \u0026#34;director is required\u0026#34;  } }  All requests which incur errors as a result of an internal server or database error should return a 500 Internal Server Error and not leak any information about the database or internal systems to the client. These errors should return a response body which looks like the following:  {  \u0026#34;error\u0026#34;: {  \u0026#34;kind\u0026#34;: \u0026#34;internal_error\u0026#34;,  \u0026#34;message\u0026#34;: \u0026#34;internal server error - please contact support\u0026#34;  } } All errors should return a Request-Id response header with a unique request id that can be used for debugging to find the corresponding error in logs.\nImplementation All errors should be raised using custom errors from the domain/errs package. The three custom errors correspond directly to the requirements above.\nTypical Errors Typically, errors raised throughout go-api-basic are the custom errs.Error, which looks like:\ntype Error struct {  // User is the username of the user attempting the operation.  User UserName  // Kind is the class of error, such as permission failure,  // or \u0026#34;Other\u0026#34; if its class is unknown or irrelevant.  Kind Kind  // Param represents the parameter related to the error.  Param Parameter  // Code is a human-readable, short representation of the error  Code Code  // The underlying error that triggered this one, if any.  Err error } These errors are raised using the E function from the domain/errs package. errs.E is taken from Rob Pike\u0026rsquo;s upspin errors package (but has been changed based on my requirements). The errs.E function call is variadic and can take several different types to form the custom errs.Error struct.\nHere is a simple example of creating an error using errs.E:\nerr := errs.E(\u0026#34;seems we have an error here\u0026#34;) When a string is sent, an error will be created using the errors.New function from github.com/pkg/errors and added to the Err element of the struct, which allows retrieval of the error stacktrace later on. In the above example, User, Kind, Param and Code would all remain unset.\nYou can set any of these custom errs.Error fields that you like, for example:\nfunc (m *Movie) SetReleased(r string) (*Movie, error) {  t, err := time.Parse(time.RFC3339, r)  if err != nil {  return nil, errs.E(errs.Validation,  errs.Code(\u0026#34;invalid_date_format\u0026#34;),  errs.Parameter(\u0026#34;release_date\u0026#34;),  err)  }  m.Released = t  return m, nil } Above, we used errs.Validation to set the errs.Kind as Validation. Valid error Kind are:\nconst (  Other Kind = iota // Unclassified error. This value is not printed in the error message.  Invalid // Invalid operation for this type of item.  IO // External I/O error such as network failure.  Exist // Item already exists.  NotExist // Item does not exist.  Private // Information withheld.  Internal // Internal error or inconsistency.  BrokenLink // Link target does not exist.  Database // Error from database.  Validation // Input validation error.  Unanticipated // Unanticipated error.  InvalidRequest // Invalid Request ) errs.Code represents a short code to respond to the client with for error handling based on codes (if you choose to do this) and is any string you want to pass.\nerrs.Parameter represents the parameter that is being validated or has problems, etc.\n Note in the above example, instead of passing a string and creating a new error inside the errs.E function, I am directly passing the error returned by the time.Parse function to errs.E. The error is then added to the Err field using errors.WithStack from the github.com/pkg/errors package. This will enable stacktrace retrieval later as well.\n There are a few helpers in the errs package as well, namely the errs.MissingField function which can be used when validating missing input on a field. This idea comes from this Mat Ryer post and is pretty handy.\nHere is an example in practice:\n// IsValid performs validation of the struct func (m *Movie) IsValid() error {  switch {  case m.Title == \u0026#34;\u0026#34;:  return errs.E(errs.Validation, errs.Parameter(\u0026#34;title\u0026#34;), errs.MissingField(\u0026#34;title\u0026#34;)) The error message for the above would read title is required\nThere is also errs.InputUnwanted which is meant to be used when a field is populated with a value when it is not supposed to be.\nTypical Error Flow As errors created with errs.E move up the call stack, they can just be returned, like the following:\nfunc inner() error {  return errs.E(\u0026#34;seems we have an error here\u0026#34;) }  func middle() error {  err := inner()  if err != nil {  return err  }  return nil }  func outer() error {  err := middle()  if err != nil {  return err  }  return nil }  In the above example, the error is created in the inner function - middle and outer return the error as is typical in Go.\n You can add additional context fields (errs.Code, errs.Parameter, errs.Kind) as the error moves up the stack, however, I try to add as much context as possible at the point of error origin and only do this in rare cases.\nHandler Flow At the top of the program flow for each service is the app service handler (for example, Server.handleMovieCreate). In this handler, any error returned from any function or method is sent through the errs.HTTPErrorResponse function along with the http.ResponseWriter and a zerolog.Logger.\nFor example:\nresponse, err := s.CreateMovieService.Create(r.Context(), rb, u) if err != nil {  errs.HTTPErrorResponse(w, logger, err)  return } errs.HTTPErrorResponse takes the custom error (errs.Error, errs.Unauthenticated or errs.UnauthorizedError), writes the response to the given http.ResponseWriter and logs the error using the given zerolog.Logger.\n return must be called immediately after errs.HTTPErrorResponse to return the error to the client.\n Typical Error Response For the errs.Error type, errs.HTTPErrorResponse writes the HTTP response body as JSON using the errs.ErrResponse struct.\n// ErrResponse is used as the Response Body type ErrResponse struct {  Error ServiceError `json:\u0026#34;error\u0026#34;` }  // ServiceError has fields for Service errors. All fields with no data will // be omitted type ServiceError struct {  Kind string `json:\u0026#34;kind,omitempty\u0026#34;`  Code string `json:\u0026#34;code,omitempty\u0026#34;`  Param string `json:\u0026#34;param,omitempty\u0026#34;`  Message string `json:\u0026#34;message,omitempty\u0026#34;` } When the error is returned to the client, the response body JSON looks like the following:\n{  \u0026#34;error\u0026#34;: {  \u0026#34;kind\u0026#34;: \u0026#34;input_validation_error\u0026#34;,  \u0026#34;code\u0026#34;: \u0026#34;invalid_date_format\u0026#34;,  \u0026#34;param\u0026#34;: \u0026#34;release_date\u0026#34;,  \u0026#34;message\u0026#34;: \u0026#34;parsing time \\\u0026#34;1984a-03-02T00:00:00Z\\\u0026#34; as \\\u0026#34;2006-01-02T15:04:05Z07:00\\\u0026#34;: cannot parse \\\u0026#34;a-03-02T00:00:00Z\\\u0026#34; as \\\u0026#34;-\\\u0026#34;\u0026#34;  } } In addition, the error is logged. If zerolog.ErrorStackMarshaler is set to log error stacks (more about this in a later post), the logger will log the full error stack, which can be super helpful when trying to identify issues.\nThe error log will look like the following (I cut off parts of the stack for brevity):\n{  \u0026#34;level\u0026#34;: \u0026#34;error\u0026#34;,  \u0026#34;ip\u0026#34;: \u0026#34;127.0.0.1\u0026#34;,  \u0026#34;user_agent\u0026#34;: \u0026#34;PostmanRuntime/7.26.8\u0026#34;,  \u0026#34;request_id\u0026#34;: \u0026#34;bvol0mtnf4q269hl3ra0\u0026#34;,  \u0026#34;stack\u0026#34;: [{  \u0026#34;func\u0026#34;: \u0026#34;E\u0026#34;,  \u0026#34;line\u0026#34;: \u0026#34;172\u0026#34;,  \u0026#34;source\u0026#34;: \u0026#34;errs.go\u0026#34;  }, {  \u0026#34;func\u0026#34;: \u0026#34;(*Movie).SetReleased\u0026#34;,  \u0026#34;line\u0026#34;: \u0026#34;76\u0026#34;,  \u0026#34;source\u0026#34;: \u0026#34;movie.go\u0026#34;  }, {  \u0026#34;func\u0026#34;: \u0026#34;(*MovieController).CreateMovie\u0026#34;,  \u0026#34;line\u0026#34;: \u0026#34;139\u0026#34;,  \u0026#34;source\u0026#34;: \u0026#34;create.go\u0026#34;  }, {  ...  }],  \u0026#34;error\u0026#34;: \u0026#34;parsing time \\\u0026#34;1984a-03-02T00:00:00Z\\\u0026#34; as \\\u0026#34;2006-01-02T15:04:05Z07:00\\\u0026#34;: cannot parse \\\u0026#34;a-03-02T00:00:00Z\\\u0026#34; as \\\u0026#34;-\\\u0026#34;\u0026#34;,  \u0026#34;HTTPStatusCode\u0026#34;: 400,  \u0026#34;Kind\u0026#34;: \u0026#34;input_validation_error\u0026#34;,  \u0026#34;Parameter\u0026#34;: \u0026#34;release_date\u0026#34;,  \u0026#34;Code\u0026#34;: \u0026#34;invalid_date_format\u0026#34;,  \u0026#34;time\u0026#34;: 1609650267,  \u0026#34;severity\u0026#34;: \u0026#34;ERROR\u0026#34;,  \u0026#34;message\u0026#34;: \u0026#34;Response Error Sent\u0026#34; }  Note: E will usually be at the top of the stack as it is where the errors.New or errors.WithStack functions are being called.\n Internal or Database Error Response There is logic within errs.HTTPErrorResponse to return a different response body if the errs.Kind is Internal or Database. As per the requirements, we should not leak the error message or any internal stack, etc. when an internal or database error occurs. If an error comes through and is an errs.Error with either of these error Kind or is unknown error type in any way, the response will look like the following:\n{  \u0026#34;error\u0026#34;: {  \u0026#34;kind\u0026#34;: \u0026#34;internal_error\u0026#34;,  \u0026#34;message\u0026#34;: \u0026#34;internal server error - please contact support\u0026#34;  } }  Unauthenticated Errors type UnauthenticatedError struct {  // WWWAuthenticateRealm is a description of the protected area.  // If no realm is specified, \u0026#34;DefaultRealm\u0026#34; will be used as realm  WWWAuthenticateRealm string   // The underlying error that triggered this one, if any.  Err error } The spec for 401 Unauthorized calls for a WWW-Authenticate response header along with a realm. The realm should be set when creating an Unauthenticated error. The errs.NewUnauthenticatedError function initializes an UnauthenticatedError.\n I generally like to follow the Go idiom for brevity in all things as much as possible, but for Unauthenticated vs. Unauthorized errors, it\u0026rsquo;s confusing enough as it is already, I don\u0026rsquo;t take any shortcuts.\n func NewUnauthenticatedError(realm string, err error) *UnauthenticatedError {  return \u0026amp;UnauthenticatedError{WWWAuthenticateRealm: realm, Err: err} } Unauthenticated Error Flow The errs.Unauthenticated error should only be raised at points of authentication as part of a middleware handler. I will get into application flow in detail later, but authentication for go-api-basic happens in middleware handlers prior to calling the app handler for the given route.\n The WWW-Authenticate realm is set to the request context using the defaultRealmHandler middleware in the app package prior to attempting authentication. Next, the Oauth2 access token is retrieved from the Authorization http header using the accessTokenHandler middleware. There are several access token validations in this middleware, if any are not successful, the errs.Unauthenticated error is returned using the realm set to the request context. Finally, if the access token is successfully retrieved, it is then converted to a User via the GoogleAccessTokenConverter.Convert method in the gateway/authgateway package. This method sends an outbound request to Google using their API; if any errors are returned, an errs.Unauthenticated error is returned.   In general, I do not like to use context.Context, however, it is used in go-api-basic to pass values between middlewares. The WWW-Authenticate realm, the Oauth2 access token and the calling user after authentication, all of which are request-scoped values, are all set to the request context.Context.\n Unauthenticated Error Response Per requirements, go-api-basic does not return a response body when returning an Unauthenticated error. The error response from cURL looks like the following:\nHTTP/1.1 401 Unauthorized Request-Id: c30hkvua0brkj8qhk3e0 Www-Authenticate: Bearer realm=\u0026#34;go-api-basic\u0026#34; Date: Wed, 09 Jun 2021 19:46:07 GMT Content-Length: 0  Unauthorized Errors type UnauthorizedError struct {  // The underlying error that triggered this one, if any.  Err error } The errs.NewUnauthorizedError function initializes an UnauthorizedError.\nUnauthorized Error Flow The errs.Unauthorized error is raised when there is a permission issue for a user when attempting to access a resource. Currently, go-api-basic\u0026rsquo;s placeholder authorization implementation Authorizer.Authorize in the domain/auth package performs rudimentary checks that a user has access to a resource. If the user does not have access, the errs.Unauthorized error is returned.\nPer requirements, go-api-basic does not return a response body when returning an Unauthorized error. The error response from cURL looks like the following:\nHTTP/1.1 403 Forbidden Request-Id: c30hp2ma0brkj8qhk3f0 Date: Wed, 09 Jun 2021 19:54:50 GMT Content-Length: 0  404 Error Illustration by Pixeltrue from Ouch!\n","date":"June 21, 2021","hero":"/posts/errors/hero.svg","permalink":"https://gilcrest.github.io/posts/errors/","summary":"Handling errors is really important in Go. Errors are first class citizens and there are many different approaches for handling them. Initially I started off basing my error handling almost entirely on a blog post from Rob Pike and created a carve-out from his code to meet my needs. It served me well for a long time, but found over time I wanted a way to easily get a stacktrace of the error, which led me to Dave Cheney\u0026rsquo;s https://github.","tags":null,"title":"REST API Error Handling in Go"},{"categories":null,"contents":"Inspiration I was inspired recently after listening to Go Time FM episode #167 and Johnny Boursiquot\u0026rsquo;s callout:\n \u0026ldquo;If you are out there, and I\u0026rsquo;m speaking to you listener, or watcher, if you are out there and thinking/meaning to muster up the energy or overcome the imposter syndrome to write a blog post that\u0026rsquo;s beginner, but you\u0026rsquo;re thinking \u0026ldquo;Oh man, everyone\u0026rsquo;s already written a beginner blog post on this thing, my voice doesn\u0026rsquo;t really matter I\u0026rsquo;m not going to really add anything to that\u0026rdquo; - you need to get over that. There\u0026rsquo;s always room for new ideas. There\u0026rsquo;s always room for new thinking, new approaches. Right, even if you think you\u0026rsquo;re rehashing something else somebody has said, I haven\u0026rsquo;t read your take on that thing. I\u0026rsquo;ve read dozens more, but I don\u0026rsquo;t mind reading another one, so get over that fear, right - put something out there. Whatever form or shape that you\u0026rsquo;d like, just contribute your part of the story. We want your part of the story, so contribute that.\u0026rdquo; - Johnny Boursiquot\n Reflection When I started with Go in 2016, it seemed like the expected path to learning was to read the standard library and paste knowledge together from various blog posts, books, etc. In-person trainings were limited and expensive. From experience though, I\u0026rsquo;ve found that trying to pick up Go knowledge through just reading and coding is extremely inefficient. It\u0026rsquo;s the combination of \u0026ldquo;digging in the docs\u0026rdquo; and putting yourself \u0026ldquo;out there\u0026rdquo; that seems to be the magic combination.\nIf you\u0026rsquo;re like me though, putting yourself \u0026ldquo;out there\u0026rdquo; in the technology arena can be terrifying. I have a degree in Hotel \u0026amp; Restaurant Management. I spent years in hotels and restaurants until I fell into IT in 2000. Ever since, I\u0026rsquo;ve been writing code in everything from Cobol to Java to now Go as well as worked my way into management, but through all that time and experience - without a Computer Science degree - I still feel out of place. In my early days of Go learning, I always felt outclassed somehow, as if I wasn\u0026rsquo;t technical enough. There was, to me, a sense that by reading the standard library and with enough experience, I would eventually start writing \u0026ldquo;idiomatic\u0026rdquo; code. I had no way of knowing exactly when I had reached this point of enlightenment, but I told myself I\u0026rsquo;d eventually get there. The reality though, is that Johnny is right, I need to get over that - I\u0026rsquo;ve wasted far too much time trying to get there. It doesn\u0026rsquo;t help that I\u0026rsquo;ve been writing Go code now for more than 4 years, but with the exception of a few short, quick conversations, I\u0026rsquo;ve never actually talked to another Go developer about Go! Honestly. I\u0026rsquo;ve had a few random chats about Go at a Meetup where I felt completely awkward and had paralyzing imposter syndrome, but in general, I\u0026rsquo;ve worked alone at home, in my spare time, trying to learn Go by reading everything I could get my hands on. I\u0026rsquo;ve read many of the Go books, most of the blog posts out there and have tried contributing where I could in open source projects to get some exposure and learnings.\nI have been working my way to this point all along though and through all of it, the Go community though has been really fantastic - every time I\u0026rsquo;ve reached out for help in a forum, I\u0026rsquo;ve found it. Every time I tried to contribute to an open source library, the help has been welcomed. Each of those interactions were actually exponentially more helpful than just reading posts, so thank you to all those out there trying to do their part in the community. I now realize that everything I publish does not have to be perfect or even guaranteed to be the most mature idea possible as every engineer innately understands that time and experience make for better code. That\u0026rsquo;s the beauty of putting yourself \u0026ldquo;out there\u0026rdquo; actually - you\u0026rsquo;re giving examples of your humanity in the code you write. Mat Ryer, for instance, I have been following and learning from him for years, and his coding has evolved in the open - take his \u0026ldquo;How I write Go HTTP services after n years\u0026rdquo; posts - he\u0026rsquo;s annually updating and refining his code publicly in writing - it\u0026rsquo;s great!\nTemplate/Boilerplate Project I was attracted to Go originally because of it\u0026rsquo;s welcoming, inclusive community and Go\u0026rsquo;s design ethos. See this Rob Pike post for what I mean by the latter. In particular, this quote:\n \u0026ldquo;Go was designed to help write big programs, written and maintained by big teams.\u0026rdquo;\n I spent 20+ years working with very large teams in my former job, designing and working with really large codebases and databases. I love designing and building processes and code templates for teams that make their lives easier, so Go is a natural fit for me.\nI had big dreams when I started my template/boilerplate repo https://github.com/gilcrest/go-api-basic - I wrote this silly little post on October 20, 2017 for v0.0.2:\n Hello Gopher community! This represents my first code release, albeit a minor one. I’m hopeful that this will be helpful. I believe in templates and am trying to put together a working API template from all the best practices I’ve found in the Go community.\n My idea was to create a boilerplate/template repo that was a fully functioning web server implementation with all the scaffolding needed for large teams and projects (security, logging, tests, db integration, etc.) using as few frameworks as possible. At the time, there weren\u0026rsquo;t a ton of these - there are a bunch now and they all bring different points of view! I named it go-api-basic as I originally had ideas for a basic and an advanced version.\nGuess what?! It\u0026rsquo;s almost 4 years later and I\u0026rsquo;m STILL working on the basic version! Yikes. It\u0026rsquo;s been evolving over the years and has taken various shapes - at one point when modules were first introduced, I tried to make EVERYTHING a module. I separated everything out into multiple repos and tried to make it super modular and highly composable. It was a productivity nightmare. At another point, I tried to do a Go version of \u0026ldquo;clean code\u0026rdquo; and had a very layered, complex structure that also ended up feeling unproductive. I\u0026rsquo;ve tried going with the \u0026ldquo;flat approach\u0026rdquo;, which is the opposite of that, but that didn\u0026rsquo;t quite work for me either. I\u0026rsquo;m now somewhere in the middle of all that, but what I have I like. I\u0026rsquo;m positive I\u0026rsquo;ll make more changes and hopefully, after I get feedback from other humans, it will get even better, but I would really love feedback. Give me negative feedback! Give me positive feedback! I really don\u0026rsquo;t care, I would love to get other perspectives on it.\nI\u0026rsquo;m going to write a series of blog posts that describe the project and then fold those posts into the project README. I just launched my new site dangillis.dev (using HUGO of course!) and my first new post (not counting this) is https://dangillis.dev/posts/errors/ - about how I do error handling in the project. I\u0026rsquo;m planning a series of fast-followers after.\nStay tuned and thanks!\nDan\n","date":"June 21, 2021","hero":"/posts/gopherhole/hero.jpeg","permalink":"https://gilcrest.github.io/posts/gopherhole/","summary":"Inspiration I was inspired recently after listening to Go Time FM episode #167 and Johnny Boursiquot\u0026rsquo;s callout:\n \u0026ldquo;If you are out there, and I\u0026rsquo;m speaking to you listener, or watcher, if you are out there and thinking/meaning to muster up the energy or overcome the imposter syndrome to write a blog post that\u0026rsquo;s beginner, but you\u0026rsquo;re thinking \u0026ldquo;Oh man, everyone\u0026rsquo;s already written a beginner blog post on this thing, my voice doesn\u0026rsquo;t really matter I\u0026rsquo;m not going to really add anything to that\u0026rdquo; - you need to get over that.","tags":null,"title":"Emerging from my Gopher Hole"},{"categories":null,"contents":"Today I converted my old posts from jekyll to HUGO and archived them for posterity. It\u0026rsquo;s fun to look back at some of those posts now \u0026ndash; so much has changed for me\u0026hellip;\nMy new site is going to start minimalist and I\u0026rsquo;ll add to it over time.\nI\u0026rsquo;m using the Toha theme, which has great guides\n","date":"May 27, 2021","hero":"/posts/conversion/hero.svg","permalink":"https://gilcrest.github.io/posts/conversion/","summary":"Today I converted my old posts from jekyll to HUGO and archived them for posterity. It\u0026rsquo;s fun to look back at some of those posts now \u0026ndash; so much has changed for me\u0026hellip;\nMy new site is going to start minimalist and I\u0026rsquo;ll add to it over time.\nI\u0026rsquo;m using the Toha theme, which has great guides","tags":null,"title":"Jekyll to Hugo Conversion"},{"categories":null,"contents":"I built my first Go library! httplog provides middleware which logs http requests and responses along with a few other features I find useful. I thought it might be helpful for some. At the very least, I tried to document the library reasonably well, spending a lot of time developing the README and ensuring the GoDoc was in good shape. I learned a lot through this exercise.\nI also restructured my Go API template repository to try and shape it based on Mat Ryer’s fantastic “How I write Go HTTP services after seven years” post. I think/hope that I got the fundamentals right from the lessons he was trying to impart and have baked them into this template repo.\nAt a high level, using the template and httplog library, you can send a request that looks like this:\nand get a response body that looks like this:\nIf turned on, the request and/or response are logged either to stdout or a PostgreSQL database (or both) and can then be used for investigative purposes, etc. You can also set options whether or not to log request/response headers and body. For instance, this example service takes password in the body, you should not log this and would turn off request body logging for this API.\nAs I mentioned above, I found the post from Mat Ryer to be extremely compelling and completely restructured my template. I now have a server struct, a la:\nI have a routes.go file where all my routing lives…\nand my handlers hang off the server with request and response structs defined within the handler…\nI haven’t incorporated everything (still need to get to the testing stuff, etc.), but it’s a good start.\nThere’s a lot more happening in the Go API template (password hashing, graceful error handling, etc.) and I plan to bake even more into it as I continue to learn. For instance, this week’s release of Go Cloud’s Wire makes me want to revisit my template again and add in dependency injection. I just added it to my list, actually….\nFinally, I’ve been coding Go in a vacuum for a year as I don’t actually know anyone else who writes Go. I know it’s cliche, but I really do welcome feedback to help me learn. Thanks!\n","date":"October 13, 2018","hero":"/images/default-hero.jpg","permalink":"https://gilcrest.github.io/posts/archive/http-logging-and-go-api-template-updates/","summary":"I built my first Go library! httplog provides middleware which logs http requests and responses along with a few other features I find useful. I thought it might be helpful for some. At the very least, I tried to document the library reasonably well, spending a lot of time developing the README and ensuring the GoDoc was in good shape. I learned a lot through this exercise.\nI also restructured my Go API template repository to try and shape it based on Mat Ryer’s fantastic “How I write Go HTTP services after seven years” post.","tags":null,"title":"HTTP Logging and Go API Template Updates"},{"categories":null,"contents":"Redis is pretty great. It is the #1 most loved database for the second year in a row, according to a recent Stack Overflow survey. I decided it was high time I taught myself how to use it with Go.\nThere are a number of libraries in the Go ecosystem for Redis, but the two most popular are go-redis and redigo. Each library has a decent amount of stars, contributors, etc. but from what I can tell redigo seems to have a slight edge in terms of documentation and community acceptance. For instance, the mighty Redis Labs, has a couple of posts describing interacting with Redis via Go using redigo — it’s not a direct endorsement, but pretty close… I tried both libraries actually, but found redigo was better documented. That said, in order to get up and running quickly with redigo, having to troll through godoc was a bit cumbersome (I’m still getting my head around analyzing godoc TBH). In this post, I’ll attempt to give some simple examples for redigo that may prove helpful to some.\nBelow I take you through creating a connection pool, testing connectivity via the PING command, adding a simple Key:Value pair via the SET command, retrieving a given value given the GET command and finally storing a struct as JSON using the SET command and retrieving the same struct with the GET command.\nTL;DR — For the full main.go with all the examples below, you can find them here.\nPOOL To establish connectivity in redigo, you need to create a redis.Pool object which is a pool of connections to Redis. In order to do this, you can use something like the following:\nfunc newPool() *redis.Pool {  return \u0026amp;redis.Pool{  // Maximum number of idle connections in the pool.  MaxIdle: 80,  // max number of connections  MaxActive: 12000,  // Dial is an application supplied function for creating and  // configuring a connection.  Dial: func() (redis.Conn, error) {  c, err := redis.Dial(\u0026#34;tcp\u0026#34;, \u0026#34;:6379\u0026#34;)  if err != nil {  panic(err.Error())  }  return c, err  },  } } Use the Get method of the Pool object to grab a connection from the pool. Per the redigo documentation, “The application must call the connection Close method when the application is done with the connection.”\nfunc main() {  pool := newPool()  conn := pool.Get()  defer conn.Close()  err := ping(conn)  if err != nil {  fmt.Println(err)  } ... PING If you wish you to simply check connectivity, you can use Redis’ PING command.\n// ping tests connectivity for redis (PONG should be returned) func ping(c redis.Conn) error {  // Send PING command to Redis  pong, err := c.Do(\u0026#34;PING\u0026#34;)  if err != nil {  return err  }   // PING command returns a Redis \u0026#34;Simple String\u0026#34;  // Use redis.String to convert the interface type to string  s, err := redis.String(pong, err)  if err != nil {  return err  }   fmt.Printf(\u0026#34;PING Response = %s\\n\u0026#34;, s)  // Output: PONG   return nil } To break down what’s happening here — the function takes in a redis Conn type (connection). We are calling the Do method of Conn, which takes a Redis command as it’s first argument. The redigo client communicates to Redis using Redis’ RESP protocol. Redis then responds with one of several types (Simple Strings, Errors, Integers, Bulk Strings and Arrays), which are mapped to Go types. The response from the Do method does not give back the specific Go type though, but rather an interface{} type. We can use a type assertion to determine the response type from the Do method, but seeing as we know from the Redis documentation that the Return Value from PING is a simple string, we can use one of redigo’s handy helper functions (redis.String) to perform a type conversion to string for us.\nFor illustrative purposes in my example above, I executed the helper redis.String function separately from the Do method as I found it easier to understand on my first pass. In reality, you’ll use the redigo provided helper functions to wrap your Do method calls (provided you know the response type), as I have done in the example below. Any remaining examples will use this shortened form where appropriate.\n// ping tests connectivity for redis (PONG should be returned) func ping(c redis.Conn) error {  // Send PING command to Redis  // PING command returns a Redis \u0026#34;Simple String\u0026#34;  // Use redis.String to convert the interface type to string  s, err := redis.String(c.Do(\u0026#34;PING\u0026#34;))  if err != nil {  return err  }   fmt.Printf(\u0026#34;PING Response = %s\\n\u0026#34;, s)  // Output: PONG   return nil } SET Use the Redis SET command to add a key:value pair to Redis. Below is a trivial example of adding a key (“Favorite Movie”) and a string value for it (“Repo Man”) as well as an int value (1984 as the movie Release Year). The blank identifier is used for the reply as we only need to check for errors (“OK” is the only thing that comes back on a successful SET command reply).\n// set executes the redis SET command func set(c redis.Conn) error {  _, err := c.Do(\u0026#34;SET\u0026#34;, \u0026#34;Favorite Movie\u0026#34;, \u0026#34;Repo Man\u0026#34;)  if err != nil {  return err  }  _, err = c.Do(\u0026#34;SET\u0026#34;, \u0026#34;Release Year\u0026#34;, 1984)  if err != nil {  return err  }  return nil } GET In order to retrieve a value for a given key, use the Redis GET command. Some simple examples are below, including an example where no results are retrieved. We can check for redis.ErrNil to determine if nothing is returned and should handle appropriately.\n// get executes the redis GET command func get(c redis.Conn) error {   // Simple GET example with String helper  key := \u0026#34;Favorite Movie\u0026#34;  s, err := redis.String(c.Do(\u0026#34;GET\u0026#34;, key))  if err != nil {  return (err)  }  fmt.Printf(\u0026#34;%s = %s\\n\u0026#34;, key, s)   // Simple GET example with Int helper  key = \u0026#34;Release Year\u0026#34;  i, err := redis.Int(c.Do(\u0026#34;GET\u0026#34;, key))  if err != nil {  return (err)  }  fmt.Printf(\u0026#34;%s = %d\\n\u0026#34;, key, i)   // Example where GET returns no results  key = \u0026#34;Nonexistent Key\u0026#34;  s, err = redis.String(c.Do(\u0026#34;GET\u0026#34;, key))  if err == redis.ErrNil {  fmt.Printf(\u0026#34;%s does not exist\\n\u0026#34;, key)  } else if err != nil {  return err  } else {  fmt.Printf(\u0026#34;%s = %s\\n\u0026#34;, key, s)  }   return nil } STRUCT (SET) For my purposes of building a look-aside cache, I want to store objects in cache in their entirety in Redis. There seem to be a few different viewpoints on doing this — one where you store your object using a Redis Hash data type and the HMSET command. This is nice because, if need be you can update individual values within the object independently. I have seen examples of people using the redigo AddFlat method of the redigo.Args type to accomplish this, but also noted in redigo’s FAQ that redigo does not actually provide a way to serialize structs to Redis, so I stayed away from trying this.\nFor my purposes, I am ok with just storing the data as an object in its entirety and thus decided to store my data as JSON using the SET command.\nThe example below shows storing a user, with username “otto”, with a key of “user:otto”. Use json.Marshal to serialize your object to JSON and store the serialized version as the value.\nfunc setStruct(c redis.Conn) error {   const objectPrefix string = \u0026#34;user:\u0026#34;   usr := User{  Username: \u0026#34;otto\u0026#34;,  MobileID: 1234567890,  Email: \u0026#34;ottoM@repoman.com\u0026#34;,  FirstName: \u0026#34;Otto\u0026#34;,  LastName: \u0026#34;Maddox\u0026#34;,  }   // serialize User object to JSON  json, err := json.Marshal(usr)  if err != nil {  return err  }   // SET object  _, err = c.Do(\u0026#34;SET\u0026#34;, objectPrefix+usr.Username, json)  if err != nil {  return err  }   return nil } STRUCT (GET) The example below shows retrieving the object using the GET command and then deserializing it with json.Unmarshal\nfunc getStruct(c redis.Conn) error {   const objectPrefix string = \u0026#34;user:\u0026#34;   username := \u0026#34;otto\u0026#34;  s, err := redis.String(c.Do(\u0026#34;GET\u0026#34;, objectPrefix+username))  if err == redis.ErrNil {  fmt.Println(\u0026#34;User does not exist\u0026#34;)  } else if err != nil {  return err  }   usr := User{}  err = json.Unmarshal([]byte(s), \u0026amp;usr)   fmt.Printf(\u0026#34;%+v\\n\u0026#34;, usr)   return nil  } {Username:otto MobileID:1234567890 Email:ottoM@repoman.com FirstName:Otto LastName:Maddox}  That’s it for now. Keep in mind, I wrote this main and these little functions in a somewhat non-idiomatic way just to aid in the examples, you should streamline this in a real app.\nI also created a similar main.go for the go-redis client, that you can find here. For go-redis, storing structs as Redis hashes is easier, as you can pass a map of strings type to the HMSET command.\n","date":"July 17, 2018","hero":"/images/default-hero.jpg","permalink":"https://gilcrest.github.io/posts/archive/basic-redis-examples/","summary":"Redis is pretty great. It is the #1 most loved database for the second year in a row, according to a recent Stack Overflow survey. I decided it was high time I taught myself how to use it with Go.\nThere are a number of libraries in the Go ecosystem for Redis, but the two most popular are go-redis and redigo. Each library has a decent amount of stars, contributors, etc.","tags":null,"title":"Basic Redis Examples with Go"},{"categories":null,"contents":"I’m working through creating a RESTful API template. As part of it, I want to be able to “Containerize” my app using docker and deploy it to “the cloud”. Baby steps for me though — I want to get everything working locally first. This post is about “containerizing” my API using Docker and getting it to work locally on my Mac. Right now, from a networking perspective, my app is pretty simple — it needs connectivity on two ports: 1 port for database traffic, 1 port for http traffic.\nPart 1 — Simple build against local PostgreSQL, exposing ports 5432 for PostgreSQL and 8080 for http traffic from my local host to my container First off, you must have Docker for Mac installed. Once installed, you’ll need to familiarize yourself with the various docker commands and idioms. I highly recommend Docker Deep Dive. I read a lot of different blogs and how-tos on Docker and wasn’t able to really put it all together until I read this book.\nFor my database, I have PostgreSQL running locally on my Mac using Postgres.app — you can use whatever you like, but I find this product incredibly simple to use. I do not change any of the default settings, which means Postgres listens on port 5432.\nFor database configuration (dbname, host, port, user, password), I’m storing everything as environment variables and accessing them within my Go program via os.Getenv, e.g.:\ndbName := os.Getenv(\u0026#34;PG_DBNAME_TEST\u0026#34;) dbUser := os.Getenv(\u0026#34;PG_USERNAME_TEST\u0026#34;) dbPassword := os.Getenv(\u0026#34;PG_PASSWORD_TEST\u0026#34;) dbHost := os.Getenv(\u0026#34;PG_HOST_TEST\u0026#34;) dbPort, err := strconv.Atoi(os.Getenv(\u0026#34;PG_PORT_TEST\u0026#34;)) if err != nil {  log.Error().Err(err).Msg(\u0026#34;Unable to complete string to int conversion for dbPort\u0026#34;)  return nil, err } My Dockerfile for this part is quite simple and similar to the one on the official golang blog. I use dep (will eventually switch to vgo) to “vendor my dependencies” so as part of my build I don’t need to “go get” any external dependencies as they’re copied over as part of the ADD command when I copy the entire workspace over from my local host to the container.\n# Start from a Debian image with the latest version of Go installed# and a workspace (GOPATH) configured at /go.FROMgolang:latest# Create WORKDIR (working directory) for appWORKDIR/go/src/github.com/gilcrest/go-API-template# Copy the local package files to the container\u0026#39;s workspace# (in the above WORKDIR)ADD . .# Switch WORKDIR to directory where server main.go livesWORKDIR/go/src/github.com/gilcrest/go-API-template/cmd/server# Build the go-API-template userServer command inside the container# at the most recent WORKDIRRUN go build -o userServer# Run the userServer command by default when the container starts.# runs command at most recent WORKDIRENTRYPOINT ./userServer# Document that the container uses port 8080EXPOSE8080# Document that the container uses port 5432EXPOSE5432Let’s break down what’s happening in this file:\nFROM golang:latest — This command tells Docker to pull the golang image with the latest tag from the official Docker repository as the first layer.\nWORKDIR /go/src/github.com/gilcrest/go-API-template — This command sets the working directory to the path given. This directory doesn’t already exist, so, it will be created.\nADD . . — This command copies all the files, directories and subdirectories from the current directory where the Dockerfile is located and moves them to the WORKDIR defined above\nWORKDIR /go/src/github.com/gilcrest/go-API-template/cmd/server — This command sets the working directory to the path given. This directory exists already.\nRUN go build -o userServer — This command builds the application binary from main.go within the work directory and creates the binary with the given name userServer\nENTRYPOINT ./userServer — This command sets the container to run as an executable and runs the userServer binary created earlier\nEXPOSE 8080 and EXPOSE 5432 — These commands are really documentation only. They document that this image needs these ports exposed to function properly.\nTo build the image from my Dockerfile, I run the following command from my app’s root directory (which is where I also store my Dockerfile):\n# Build image with gilcrest as repository name, go-api-template  # as build name and latest as build tag from the current directory  $ docker image build -t gilcrest/go-api-template:latest . After successfully building my new image, I use the below command to run it:\n# Run container using previously built image (gilcrest/go-api-template) # -d Run in the background (detached) # -p publish port 5432 on the host to port 5432 on the container for postgres # -p publish port 8080 on the host to port 8080 on the container for http access # --env-file load environment variables using the env file # --name name the container user-server  $ docker container run -d -p 5432:5432 -p 8080:8080 --env-file ./test.env --name user-server gilcrest/go-api-template To quickly go through all the options as part of the run command above:\n-d: Runs the container in the background as a “detached” session or daemon\n-p: publishes ports from the host to ports on the container (host on left of colon, container on right of colon)\n-—env-file: where to pull “environment file” for setting environment variables at run time\n-—name: gives the container a unique identifier\n A couple of gotchas I’d like to point out that I ended up spending hours researching that may be helpful for some.\nTo connect to PostgreSQL running on your Mac (the docker “host”) from within a running container, you have to know the host’s IP address. Seeing as when running a container as part of Docker for Mac, you’re actually running within a lightweight VM, determining your actual host IP address can be a tricky proposition as the IP is not static. Luckily, more recent Docker for Mac versions allow you to use special DNS name host.docker.internal to determine the host IP address. See I WANT TO CONNECT FROM A CONTAINER TO A SERVICE ON THE HOST on the docker site for the full details.\nAnother challenge was actually connecting to my API endpoint running in my container from my local machine. Prior to using Docker, I had been specifying a particular IP address for my localhost when setting up http.ListenAndServe, e.g. http.ListenAndServe(“127.0.0.1:8080”, nil), but seeing as when you run your container using Docker for Mac, you’re running within a lightweight VM, it will have a different IP than the standard loopback localhost IP (127.0.0.1). I tried docker inspect but had a pretty hard time figuring out exactly what IP I would need to try and hit to make this work. I ended up removing the loopback localhost IP from the addr function parameter for http.ListenAndServe and only have the port as part of the string, as in below (“:8080”).\n// ListenAndServe on port 8080, not specifying a particular IP address for this particular implementation if err := http.ListenAndServe(\u0026#34;:8080\u0026#34;, nil); err != nil {  log.Fatal(err) } Once you’ve removed this IP, you can then use “localhost” and port 8080 to connect to your APIs running within the container. Requests will be properly forwarded (e.g. a POST tohttp://localhost:8080/api/appUser now works and hits my container API!) See I WANT TO CONNECT TO A CONTAINER FROM THE MAC on the Docker site for full details.\nOne thing to highlight from the former run command is the environment file that I use to load the environment key:value pairs from my local shell to the container’s shell environment.\n$ docker container run -d -p 5432:5432 -p 8080:8080 --env-file ./test.env --name user-server gilcrest/go-api-template This file, which simply looks like:\nPG_DBNAME_TEST PG_USERNAME_TEST PG_PASSWORD_TEST PG_HOST_TEST=host.docker.internal PG_PORT_TEST — tells Docker to pull in the above environment variables from the local shell and push them into the containers shell. For most of the variables, I am only providing the key and not the value. Docker will pull in the value from the shell environment that is running the command. For the PG_HOST_TEST variable I am providing the value (host.docker.internal) as I want to override the shell environment value on my Mac (localhost). This allows me to run my app either inside a container or just run it locally without a container as you would any non-containerized app, and it works in both cases. If I am running the app “normally” (non-containerized), the environment will have localhost as PG_HOST_TEST, if I’m running inside the container, I need host.docker.internal as the host name for the db.\nStoring my configuration in the environment like this meets the “Twelve Factor App” guidelines, which I think are generally good. I make sure I have .env files in my .gitignore file to ensure that these config values don’t get checked in as part of my app (see below for .gitignore example).\n# Docker env files *.env  Now that we’ve got the basics working, the image that is created is really pretty big — for my app it’s 882mb! If you’re building for the first time, then because of this size, the build process is also pretty slow…\nAs Gophers, naturally, we like our builds fast. In order to run smaller, faster, more secure/efficient images, Docker allows for multi-stage builds. As far as I can tell, this is pretty commonplace for running production containers and is considered a best practice.\nPart 2 — Dockerizing your app using Multi-Stage Builds Docker allows for “multi-stage builds”, meaning you can pull down multiple images and copy artifacts from one stage to another — you can read all about it here. After trolling Slack and other blogs for information, the most common way I could find was to deploy apps using the Docker Alpine Linux image. This is a tiny image — 5mb!!! This makes building a lot faster and images way smaller. There is also an official golang Docker version using Alpine — golang:alpine. This image isn’t as bare bones as the base Alpine Linux image as it has what’s needed to run Go.\nI found several different methods of running containers using Alpine, many of which started with a “normal” Go base image, but that also requires you to compile the go binary in a special way as the Alpine Linux image is based on musl libc and busybox. My understanding is that because of this, you need to run a command similar to RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app . to build your app. I don’t really know exactly what this command is doing, so I looked elsewhere.\nAn alternative is to use the golang:alpine image as your base image in your first “builder” stage and build as you normally would within it (e.g., go build -o app). As this image is already built within alpine, there seems to be no need to do the more complicated build command I mentioned above. You can then copy your app binary built within the first stage into your second stage which uses the alpine base image and it will run! My Dockerfile example is below:\n##################################################################### Builder Stage ###################################################################### Use the official Golang image to create a build artifact.# This is based on Debian and sets the GOPATH to /go.# https://hub.docker.com/_/golangFROMgolang:alpine AS builder# Create WORKDIR using project\u0026#39;s root directoryWORKDIR/go/src/github.com/gilcrest/go-API-template# Copy the local package files to the container\u0026#39;s workspace# in the above created WORKDIRADD . .# Build the go-API-template command inside the containerRUN cd cmd/server \u0026amp;\u0026amp; go build -o userServer##################################################################### Final Stage ###################################################################### Use the official Alpine image for a lean production container.# https://hub.docker.com/_/alpine# https://docs.docker.com/develop/develop-images/multistage-build/#use-multi-stage-buildsFROMalpine:3# Create WORKDIRWORKDIR/src/github.com/gilcrest/go-API-template/input# Copy json file needed for feature flags to directory expected by app# File is copied from the Builder stage imageCOPY --from=builder /go/src/github.com/gilcrest/go-API-template/input/httpLogOpt.json .# Create WORKDIRWORKDIR/app# Copy app binary from the Builder stage imageCOPY --from=builder /go/src/github.com/gilcrest/go-API-template/cmd/server/userServer .# Run the userServer command by default when the container starts.ENTRYPOINT ./userServer# Document that the service uses port 8080EXPOSE8080# Document that the service uses port 5432EXPOSE5432I went through most of the commands before, so I’ll just highlight a few things:\nFROM — There are two FROM commands — this is the essence of multi-stage builds. You can have as many FROM commands (stages) as you want… NOTE!! I have given the first stage a name using AS (FROM golang:alpine AS builder). This is important for later…\nRUN cd cmd/server \u0026amp;\u0026amp; go build -o userServer — This command is two commands in one (the \u0026amp;\u0026amp; allows for this). I first change the directory to cmd/server (remember, my working directory is the WORKDIR so I can work relative to that after the WORKDIR command). I then run the go build command sending it’s output binary to use userServer as it’s name.\nCOPY — from=builder /go/src/github.com/gilcrest/go-API-template/cmd/server/userServer . — The COPY command is used to copy files or directories from a source to a destination within the container. In this case, I’m copying from the builder stage I had name earlier to the WORKDIR I’m working in — cool! I use the COPY command to copy a json file my app needs as well as my app binary.\nAll the other instructions are pretty straightforward and work the same as I had mentioned in Part 1, including the docker build and docker run commands. The only gotcha I’ve found so far is that if you for some reason want to run your container in interactive mode using -it (instead of -d) and have it run using /bin/bash as you normally would, that won’t work on an alpine container as it’s not there! You have to use /bin/sh instead.\nThat’s it for today — my next post will be about getting this container hoisted up to “the cloud” somehow… Onwards and upwards!\n","date":"April 6, 2018","hero":"/images/default-hero.jpg","permalink":"https://gilcrest.github.io/posts/archive/containerize-go-api/","summary":"I’m working through creating a RESTful API template. As part of it, I want to be able to “Containerize” my app using docker and deploy it to “the cloud”. Baby steps for me though — I want to get everything working locally first. This post is about “containerizing” my API using Docker and getting it to work locally on my Mac. Right now, from a networking perspective, my app is pretty simple — it needs connectivity on two ports: 1 port for database traffic, 1 port for http traffic.","tags":null,"title":"Containerizing a Go API with Docker For Mac"},{"categories":null,"contents":"I like simple structured messages using JSON in error responses, similar to Stripe, Uber and many others…\n{  \u0026#34;error\u0026#34;: {  \u0026#34;type\u0026#34;: \u0026#34;validation_failed\u0026#34;,  \u0026#34;message\u0026#34;: \u0026#34;Username is a required field\u0026#34;  } } In my last story, I wrote about HTTP Logging and in that I mentioned that I have used “chained” middleware using the Adapter pattern from Mat Ryer’s excellent post. You’ll see that below, but also in addition, I’m wrapping my final true app handler (in this case, CreateUser) inside an ErrHandler type — eh.ErrHandler{Env: env, H: handler.CreateUser} (you’ll note I’m passing in a global environment type as well). I’m doing this based on another great article by Matt Silverlock on his blog here.\npackage dispatch  import (  \u0026#34;github.com/gilcrest/go-API-template/appUser/handler\u0026#34;  \u0026#34;github.com/gilcrest/go-API-template/env\u0026#34;  eh \u0026#34;github.com/gilcrest/go-API-template/server/errorHandler\u0026#34;  \u0026#34;github.com/gilcrest/go-API-template/server/middleware\u0026#34;  \u0026#34;github.com/gorilla/mux\u0026#34; )  // Dispatch is a way of organizing routing to handlers (versioning as well) func Dispatch(env *env.Env, rtr *mux.Router) *mux.Router {   // initialize new instance of APIAudit  audit := new(middleware.APIAudit)   // match only POST requests on /api/appUser/create  // This is the original (v1) version for the API and the response for this  // will never change with versioning in order to maintain a stable contract  rtr.Handle(\u0026#34;/appUser\u0026#34;, middleware.Adapt(eh.ErrHandler{Env: env, H: handler.CreateUser}, middleware.LogRequest(env, audit), middleware.LogResponse(env, audit))).  Methods(\u0026#34;POST\u0026#34;).  Headers(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;)   // match only POST requests on /api/v1/appUser/create  rtr.Handle(\u0026#34;/v1/appUser\u0026#34;, middleware.Adapt(eh.ErrHandler{Env: env, H: handler.CreateUser}, middleware.LogRequest(env, audit), middleware.LogResponse(env, audit))).  Methods(\u0026#34;POST\u0026#34;).  Headers(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;)   return rtr } I’m using Matt’s article almost word for word for error handling, but made a few tweaks so that I could return a structured JSON response. The package is below:\npackage errorHandler  import (  \u0026#34;encoding/json\u0026#34;  \u0026#34;errors\u0026#34;  \u0026#34;net/http\u0026#34;   \u0026#34;github.com/gilcrest/go-API-template/env\u0026#34; )  // Error represents a handler error. It provides methods for a HTTP status // code and embeds the built-in error interface. type Error interface {  error  Status() int  ErrType() string }  // HTTPErr represents an error with an associated HTTP status code. type HTTPErr struct {  Code int  Type string  Err error }  // Allows HTTPErr to satisfy the error interface. func (hse HTTPErr) Error() string {  return hse.Err.Error() }  // SetErr creates an error type and adds it to the struct func (hse *HTTPErr) SetErr(s string) {  hse.Err = errors.New(s) }  // ErrType returns a string error type/code func (hse HTTPErr) ErrType() string {  return hse.Type }  // Status Returns an HTTP status code. func (hse HTTPErr) Status() int {  return hse.Code }  type errResponse struct {  Error svcError `json:\u0026#34;error\u0026#34;` }  type svcError struct {  Type string `json:\u0026#34;type\u0026#34;`  Message string `json:\u0026#34;message\u0026#34;` }  // The ErrHandler struct that takes a configured Env and a function matching // our useful signature. type ErrHandler struct {  Env *env.Env  H func(e *env.Env, w http.ResponseWriter, r *http.Request) error }  // ServeHTTP allows Handler type to satisfy the http.Handler interface func (h ErrHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) {   // Get a new logger instance  log := h.Env.Logger   log.Debug().Msg(\u0026#34;Start Handler.ServeHTTP\u0026#34;)  defer log.Debug().Msg(\u0026#34;Finish Handler.ServeHTTP\u0026#34;)   err := h.H(h.Env, w, r)   if err != nil {  // We perform a \u0026#34;type switch\u0026#34; https://tour.golang.org/methods/16  // to determine the interface value type  switch e := err.(type) {  // If the interface value is of type Error (not a typical error, but  // the Error interface defined above), then  case Error:  // We can retrieve the status here and write out a specific  // HTTP status code.  log.Printf(\u0026#34;HTTP %d - %s\u0026#34;, e.Status(), e)   er := errResponse{  Error: svcError{  Type: e.ErrType(),  Message: e.Error(),  },  }   // Marshal errResponse struct to JSON for the response body  errJSON, _ := json.MarshalIndent(er, \u0026#34;\u0026#34;, \u0026#34; \u0026#34;)   http.Error(w, string(errJSON), e.Status())   default:  // Any error types we don\u0026#39;t specifically look out for default  // to serving a HTTP 500  cd := http.StatusInternalServerError  er := errResponse{  Error: svcError{  Type: \u0026#34;unknown_error\u0026#34;,  Message: \u0026#34;Unexpected error - contact support\u0026#34;,  },  }   log.Error().Msgf(\u0026#34;Unknown Error - HTTP %d - %s\u0026#34;, cd, err.Error())   // Marshal errResponse struct to JSON for the response body  errJSON, _ := json.MarshalIndent(er, \u0026#34;\u0026#34;, \u0026#34; \u0026#34;)   http.Error(w, string(errJSON), cd)  }  }  } I renamed the StatusError struct to HTTPErr and added Type (string) as a field to it. I then added an ErrType() method to the Error interface and to the HTTPErr struct in order to be able to extract the Type field. I added a couple of structs to help form the JSON (errResponse and svcError) in the manner I wanted and then populate and marshal those structs into JSON within the type switch logic. That’s it, really — Matt did all the heavy lifting, I just added some bits that I thought were helpful for my purposes.\nThis whole thing makes error handling pretty nice though — given the wrapper logic, you’ll always return a pretty good looking error. When creating errors within your app, you don’t have to have every error take this form — you can return normal errors lower down in the code and, depending on how you organize your code, you can catch and form the HTTPErr at a very high level so you’re not having to deal with populating a cumbersome struct all the way throughout your code. The below basically assumes that the usr.Create method is doing validations and as such we can add the “validation_failed” type to all errors returned from this method.\ntx, err := usr.Create(ctx, env) if err != nil {  return errorHandler.HTTPErr{  Code: http.StatusBadRequest,  Type: \u0026#34;validation_failed\u0026#34;,  Err: err,  } } I also added a SetErr method to the HTTPErr struct, which allows you to initialize the struct with some default values and add the actual error on the fly. For instance, below as part of my super high level edit checks on my service inputs, I initialize the HTTPErr object at the beginning of my function and then perform my edit checks to allow for brevity in error creation.\nfunc newUser(ctx context.Context, env *env.Env, cur *createUserRequest) (*appUser.User, error) { // declare a new instance of appUser.User usr := new(appUser.User) // initialize an errorHandler with the default Code and Type for // service validations (Err is set to nil as it will be set later) e := errorHandler.HTTPErr{  Code: http.StatusBadRequest,  Type: \u0026#34;validation_error\u0026#34;,  Err: nil, } // for each field you can go through whatever validations you wish // and use the SetErr method of the HTTPErr struct to add the proper // error text switch { // Username is required case cur.Username == \u0026#34;\u0026#34;:  e.SetErr(\u0026#34;Username is a required field\u0026#34;)  return nil, e // Username cannot be blah... case cur.Username == \u0026#34;blah\u0026#34;:  e.SetErr(\u0026#34;Username cannot be blah\u0026#34;)  return nil, e // If we get through the switch, set the field default:  usr.Username = cur.Username } ..... That’s it for now — I should note that Rob Pike and Andrew Gerrand authored a great post on error handling that is likely amazing. I need to ingest that and see how I can fold that into this as well…\n","date":"March 18, 2018","hero":"/images/default-hero.jpg","permalink":"https://gilcrest.github.io/posts/archive/http-json-error-responses/","summary":"I like simple structured messages using JSON in error responses, similar to Stripe, Uber and many others…\n{  \u0026#34;error\u0026#34;: {  \u0026#34;type\u0026#34;: \u0026#34;validation_failed\u0026#34;,  \u0026#34;message\u0026#34;: \u0026#34;Username is a required field\u0026#34;  } } In my last story, I wrote about HTTP Logging and in that I mentioned that I have used “chained” middleware using the Adapter pattern from Mat Ryer’s excellent post. You’ll see that below, but also in addition, I’m wrapping my final true app handler (in this case, CreateUser) inside an ErrHandler type — eh.","tags":null,"title":"HTTP JSON Error Responses in Go"},{"categories":null,"contents":"Fun show a couple nights ago @ Great Scott in Allston. Cover of King Crimson\u0026rsquo;s Red\u0026hellip;\nKing Crimson Cover - Red    ","date":"March 14, 2018","hero":"/images/default-hero.jpg","permalink":"https://gilcrest.github.io/posts/archive/king-crimson-red/","summary":"Fun show a couple nights ago @ Great Scott in Allston. Cover of King Crimson\u0026rsquo;s Red\u0026hellip;\nKing Crimson Cover - Red    ","tags":null,"title":"Drums: King Crimson Red Live @ Great Scott"},{"categories":null,"contents":"Hello Gopher community! This represents my first code release, albeit a minor one. I\u0026rsquo;m hopeful that this will be helpful. I believe in templates and am trying to put together a working API template from all the best practices I\u0026rsquo;ve found in the Go community. There\u0026rsquo;s more details on the github readme here\nThanks!\n","date":"October 20, 2017","hero":"/images/default-hero.jpg","permalink":"https://gilcrest.github.io/posts/archive/go-api-template/","summary":"Hello Gopher community! This represents my first code release, albeit a minor one. I\u0026rsquo;m hopeful that this will be helpful. I believe in templates and am trying to put together a working API template from all the best practices I\u0026rsquo;ve found in the Go community. There\u0026rsquo;s more details on the github readme here\nThanks!","tags":null,"title":"Go API Template v0.0.2"},{"categories":null,"contents":"Eureka! After many many brushes with many different languages over many many years, I think I finally found the language that is right for me - Go! It\u0026rsquo;s hard to say why really, but something about learning this language feels right - it\u0026rsquo;s well thought out, has a great community and is making programming fun again for me. It\u0026rsquo;s built in http libraries are incredible. I\u0026rsquo;m just beginning, but this could be my forever language :)\n","date":"January 9, 2017","hero":"/posts/archive/go/gilcrestGopher.png","permalink":"https://gilcrest.github.io/posts/archive/go/","summary":"Eureka! After many many brushes with many different languages over many many years, I think I finally found the language that is right for me - Go! It\u0026rsquo;s hard to say why really, but something about learning this language feels right - it\u0026rsquo;s well thought out, has a great community and is making programming fun again for me. It\u0026rsquo;s built in http libraries are incredible. I\u0026rsquo;m just beginning, but this could be my forever language :)","tags":null,"title":"And then there was Go..."},{"categories":null,"contents":"Had a great practice and took some fun footage of us playing Frankenstein.\nEdgar Winter Cover - Frankenstein    ","date":"April 28, 2016","hero":"/images/default-hero.jpg","permalink":"https://gilcrest.github.io/posts/archive/frankenstein/","summary":"Had a great practice and took some fun footage of us playing Frankenstein.\nEdgar Winter Cover - Frankenstein    ","tags":null,"title":"Drums: Frankenstein Practice"},{"categories":null,"contents":"After stumbling through the setup of Oracle (for use with node and node-oracledb) on my new and first ever Macbook, I thought I\u0026rsquo;d put together a one pager on setup for those who may have had similar struggles. I was able to find everything I needed through existing pages, but I bounced around a lot to several different sites to find all the information and it took me several attempts. I tried to cobble all the steps together in a fairly verbose way as I had to learn certain things along the way\u0026hellip;\nHere it is - https://github.com/gilcrest/OracleMacOSXElCapitanSetup4Node\n","date":"April 5, 2016","hero":"/images/default-hero.jpg","permalink":"https://gilcrest.github.io/posts/archive/osx-oracle-node-setup/","summary":"After stumbling through the setup of Oracle (for use with node and node-oracledb) on my new and first ever Macbook, I thought I\u0026rsquo;d put together a one pager on setup for those who may have had similar struggles. I was able to find everything I needed through existing pages, but I bounced around a lot to several different sites to find all the information and it took me several attempts. I tried to cobble all the steps together in a fairly verbose way as I had to learn certain things along the way\u0026hellip;","tags":null,"title":"Setting up OS X El Capitan for node development with node-oracledb"},{"categories":null,"contents":"Fun show last night @ O\u0026rsquo;Brien\u0026rsquo;s in Allston. Friend of mine grabbed this clip with his phone. There is some troubling drum face happening here\u0026hellip;\nJohn McLaughlin Cover - Raju    ","date":"March 16, 2016","hero":"/images/default-hero.jpg","permalink":"https://gilcrest.github.io/posts/archive/drums-raju-live/","summary":"Fun show last night @ O\u0026rsquo;Brien\u0026rsquo;s in Allston. Friend of mine grabbed this clip with his phone. There is some troubling drum face happening here\u0026hellip;\nJohn McLaughlin Cover - Raju    ","tags":null,"title":"Drums: Raju Live @ O'Brien's"},{"categories":null,"contents":"You may find yourself in a situation where you proudly unveil your upgraded-to-Universal Theme app to your user-base after working on it for months with your beautiful wide screen monitor (page designer pretty much mandates this) and your user-base is not quite as happy as you thought they\u0026rsquo;d be as they don\u0026rsquo;t all have super wide screens and they, for some reason, have low-resolution monitors (like 1280 x 768 low). The users may think your super cool left sidebar navigation, which is maximized by default, is neat, but they\u0026rsquo;d actually prefer their space back\u0026hellip; If you should find yourself in this situation, there is an easy answer! By default, always have that left sidebar nav minimized (I actually prefer this anyway). I turned to the Oracle APEX forum recently for the best solution to do this and forum-master, fac586 gave me a simple solution I thought I\u0026rsquo;d share for others who may need/want to do this. I\u0026rsquo;d actually love to see a declarative way of doing this in a future release of APEX (I\u0026rsquo;ll log a feature request), but until then\u0026hellip;\nFrom fac586: The simplest way to do this is with a dynamic action that simulates clicking on the button when the page is loaded with the menu expanded. Create a dynamic action as follows:\nEvent: Page Load Condition: JavaScript Expression Value: $(\u0026#39;#t_Button_navControl\u0026#39;).attr(\u0026#39;aria-expanded\u0026#39;) === \u0026#34;true\u0026#34;  True Action  Action: Execute JavaScript Code Fire On Page Load: No Code: $(\u0026#39;#t_Button_navControl\u0026#39;).click(); If you want to do this on every page of the application, simply create a global page (unless you already have one) and use the above configuration. You\u0026rsquo;ll need to use a condition so that this event does not fire on public pages (login and error pages, for example)\n","date":"October 15, 2015","hero":"/images/default-hero.jpg","permalink":"https://gilcrest.github.io/posts/archive/apex-minimize/","summary":"You may find yourself in a situation where you proudly unveil your upgraded-to-Universal Theme app to your user-base after working on it for months with your beautiful wide screen monitor (page designer pretty much mandates this) and your user-base is not quite as happy as you thought they\u0026rsquo;d be as they don\u0026rsquo;t all have super wide screens and they, for some reason, have low-resolution monitors (like 1280 x 768 low). The users may think your super cool left sidebar navigation, which is maximized by default, is neat, but they\u0026rsquo;d actually prefer their space back\u0026hellip; If you should find yourself in this situation, there is an easy answer!","tags":null,"title":"Apex 5 - Minimize Left Sidebar Navigation by Default"},{"categories":null,"contents":"I just released an early version of my \u0026ldquo;raiser\u0026rdquo; code for Oracle PL/SQL, leveraging OraOpenSource\u0026rsquo;s logger utility. I\u0026rsquo;d love to get anyone\u0026rsquo;s input and help with it. The Github project is https://github.com/gilcrest/raiser\nAs background, I\u0026rsquo;ve used the Quest Error Manager (QEM) in my codebase for years, but have recently switched primarily to using logger for most things. There are a few things that QEM does that logger does not\u0026hellip; In a highly distributed environment, you really need to be able to raise an exception to a user with a particular error message and unique identifier. If an exception is thrown in one of my applications at 4 in the morning, I need that user to be able to contact support with a unique ID and I need to be able to get a full trace of that error for proper debugging and resolution.\nClose to a year ago, I reached out to Martin D\u0026rsquo;Souza to ask if I could work with him to enhance the logger product to be able to achieve this type of implementation. Martin, being a fantastic product owner, pushed back saying he didn\u0026rsquo;t want logger to be a \u0026ldquo;raiser\u0026rdquo;, but was soon to release a new version of logger that would have hooks in it (in the form of a plugin) that I could use to achieve my goals\u0026hellip; Great! So, he did what he said he would - logger 3.0.0 and above has a really cool plugin facility that I\u0026rsquo;ve utilized to make a \u0026ldquo;raiser\u0026rdquo; out of logger.\nAlso, after reading Dan McGhan\u0026rsquo;s excellent post about using the APEX_JSON package for creating JSON content, I got the idea to encapsulate multiple fields into the Oracle exception text using JSON\u0026hellip; I had been struggling to figure out a good way to be able to give end users multiple data points with just the one SQLERRM output, but I think this works out nicely.\nI plan to add a lot more in the coming weeks to the code - for instance, an example of using the code within an APEX error handle function to return a unique logger identifier to end users. Someday, I\u0026rsquo;d also like to eventually work through some clients (java, javascript, python, etc.).\nThe first order of business is to fix the current getErrorDetails function to parse the JSON SQLERRM and how to work with it\u0026hellip;\n","date":"August 17, 2015","hero":"/images/default-hero.jpg","permalink":"https://gilcrest.github.io/posts/archive/raiser/","summary":"I just released an early version of my \u0026ldquo;raiser\u0026rdquo; code for Oracle PL/SQL, leveraging OraOpenSource\u0026rsquo;s logger utility. I\u0026rsquo;d love to get anyone\u0026rsquo;s input and help with it. The Github project is https://github.com/gilcrest/raiser\nAs background, I\u0026rsquo;ve used the Quest Error Manager (QEM) in my codebase for years, but have recently switched primarily to using logger for most things. There are a few things that QEM does that logger does not\u0026hellip; In a highly distributed environment, you really need to be able to raise an exception to a user with a particular error message and unique identifier.","tags":null,"title":"Raiser v0.5 - Committed to Github"},{"categories":null,"contents":"Next step - node.js setup on Ubuntu. This was remarkably easy! I went to https://nodejs.org/ and viewed their Downloads section, where I then went to \u0026ldquo;Installing from package managers\u0026rdquo;. That link takes you to this URL on GitHub. If you read the first line of \u0026ldquo;Debian and Ubuntu based Linux distributions\u0026rdquo;, you\u0026rsquo;ll note you should go to nodesource\u0026rsquo;s blog post for the most up to date instructions. I did what I was told - read what they have to say on the page - helpful stuff!\nThe instructions to install are as follows:\nOpen a new crosh window or use ctrl+alt+t and type:\nshell To get into Ubuntu, type:\nsudo startxfce4 Inside Ubuntu, click on the Terminal Emulator icon\nYou now need curl (a tool for making http calls, etc. - http://en.wikipedia.org/wiki/CURL), so get it - type:\nsudo apt-get install curl The instructions from nodesource\u0026rsquo;s blog post say to then enter the following:\n# Note the new setup script name for Node.js v0.12 curl -sL https://deb.nodesource.com/setup_0.12 | sudo bash - # Then install with: sudo apt-get install -y nodejs Type node to start node..\nThat\u0026rsquo;s it! node.js is installed in Ubuntu inside my chromebook!\nThere are a TON of node.js intros, etc. that I\u0026rsquo;ve been pouring over for a while now - I\u0026rsquo;m not going to bother to explain the basics of node as it\u0026rsquo;s extremely well documented. I will now start to write some small pl/sql and js programs using the node-oracledb driver and will continue to blog as things progress in that area\u0026hellip; That\u0026rsquo;s it for today!\n","date":"March 16, 2015","hero":"/images/default-hero.jpg","permalink":"https://gilcrest.github.io/posts/archive/node-oracle-glory/volume-3/","summary":"Next step - node.js setup on Ubuntu. This was remarkably easy! I went to https://nodejs.org/ and viewed their Downloads section, where I then went to \u0026ldquo;Installing from package managers\u0026rdquo;. That link takes you to this URL on GitHub. If you read the first line of \u0026ldquo;Debian and Ubuntu based Linux distributions\u0026rdquo;, you\u0026rsquo;ll note you should go to nodesource\u0026rsquo;s blog post for the most up to date instructions. I did what I was told - read what they have to say on the page - helpful stuff!","tags":null,"title":"My Path to node.js and Oracle Glory - Volume 3"},{"categories":null,"contents":"OK, so now having established my database server in Volume 1 of this series, I now need to move to the next step - setting up my chromebook with Linux in order to facilitate node.js development. I chose a chromebook as my dev machine of choice as I wanted something that natively runs on Linux, but didn\u0026rsquo;t want to pay as much as a Mac and didn\u0026rsquo;t really like the Linux based machine options out there\u0026hellip; Google is doing a great job with these and after having my chromebook for a little over a week - I have to say I love it\u0026hellip;\nThe first step is to put your chromebook into developer mode - this is a fairly frightening experience, but since everything on your chromebook is \u0026ldquo;in the cloud\u0026rdquo; and can be restored, fear not and hack on!\nI bought a Toshiba Chromebook 2 and found instructions to put the machine into developer mode at this URL and this URL as well\u0026hellip;\n To put it your chromebook into developer mode, you simply hit the esc+refresh+power keys at the same time after you\u0026rsquo;ve logged in. When you do this, your machine will reboot and show an alert screen - at this point, hit Ctrl+D to go into Developer mode. THIS WILL WIPE YOUR MACHINE! You\u0026rsquo;ll need to re-login and setup the machine again, but once done you won\u0026rsquo;t need to do this again\u0026hellip; I bought this machine to develop, so this was basically the first thing I did with it - the data wipe didn\u0026rsquo;t concern me\u0026hellip; Since most things you do are auto backed-up to Google drive, this probably won\u0026rsquo;t concern most people. The process for the laptop to transition to Developer Mode takes 15 minutes or so (one time only) - so go grab a beer\u0026hellip;  Next up - Crouton! \u0026hellip;What the hell does a crouton have to do with this? Well, crouton stands for ChRomium Os Universal chrooT envirONment - and all the information you really need about it is at the GitHub location here. This is now the point where I\u0026rsquo;m over my head, but I believe crouton is a set of scripts written by a prolific Google developer named David Schneider that allows you to create what\u0026rsquo;s known as a chroot, which allows Linux distributions to run under a segregated file system as a guest OS - more info about chroots here\nBasically, in order to run Ubuntu (the Linux distribution I\u0026rsquo;ve chosen) alongside my ChromeOS, I need to run it within a chroot. I need to use the crouton script bundle to generate this chroot.\nYou should go to https://goo.gl/fd3zc - it will download into your Downloads folder - leave it there.\nIn order to properly generate a chroot - you have to have some opinions. You need to choose a Linux distribution and a desktop environment\u0026hellip;\nI need to choose a Linux distribution? I have no idea where to start even - there are over 600 distributions of Linux and 300 are actively being developed!! Where do you even begin in this world? My understanding of a distribution of Linux is that it is a packaging of software (libraries, desktop environment, utilities, GUI, etc.). I have a lot to learn on this, but for now I\u0026rsquo;m going to be lame and choose a commercially backed option - Ubuntu. I am choosing the most recent \u0026ldquo;Long Term Support\u0026rdquo; (LTS) version of this distro, code named Trusty Tahr.\nWithin Ubuntu, there are different flavors based on the desktop environment you prefer. After some basic research, I want a basic desktop - I actually installed several different versions and thought the Unity desktop was awful\u0026hellip; So, I\u0026rsquo;m going with Xfce - a basic, yet comfortable desktop environment! This flavor of Ubuntu is known as Xubuntu\u0026hellip;\nI have my opinions settled - I know what I want - next is to go to the Chrome web store and install a few items\n Secure Shell Crosh Window - opens a separate window from your browser crouton extension - Allows for copy/paste to/from guest OS window (in my case Ubuntu)  You now have all your dependencies - you can either do Ctrl+alt+t to open a \u0026ldquo;Chrome Operating Shell\u0026rdquo; or crosh for short in a full screen window or you can use the Crosh Window app you just installed.\n At the command prompt, type shell Next type sudo sh ~/Downloads/crouton -t xiwi,xfce -r trusty  This is basically telling crouton that the target (-t) is the xfce desktop environment using the xiwi version (which allows for the copy/paste) and the distribution release (-r) should be Trusty Tahr (trusty) This takes a while to install - go get another beer\u0026hellip; At the very end of the install, you\u0026rsquo;ll be asked \u0026ldquo;Please specify a username for the primary user:\u0026rdquo; - plug in your preferred username\u0026hellip; you\u0026rsquo;ll then be asked for a password as well\u0026hellip;    Once done, you\u0026rsquo;ll be taken back to the shell prompt where you just type sudo startxfce4 and bam! Ubuntu should boot! It will boot in a full screen Chrome OS window - in order to minimize and size the window, just click at the top where it says \u0026ldquo;crouton integration\u0026rdquo; triggered full screen Exit full screen and then resize as necessary.\nEach time you log out of Ubuntu, you want to ensure you logout properly - for the distro I chose, I just go to the upper right hand corner where my username is, choose it and select Log Out\u0026hellip;\nNow that I\u0026rsquo;ve done this once, the next time is a breeze - open a new Crosh Window, type sudo startxfce4 and that\u0026rsquo;s it - I\u0026rsquo;m up and running in seconds.\nI learned a lot about this crouton extension jazz by reading this - the dude Francois Beaufort seems to be one of the chromebook leads and has a lot of great posts\u0026hellip; You probably want to follow him on Google + if you have a chromebook and are a developer.\nOK - it worked - I have Linux up and running within a Chrome OS Window! Sweet!\nThat\u0026rsquo;s it for today - next up Volume 3, Setting up node.js on Ubuntu in my Chromebook ","date":"March 14, 2015","hero":"/images/default-hero.jpg","permalink":"https://gilcrest.github.io/posts/archive/node-oracle-glory/volume-2/","summary":"OK, so now having established my database server in Volume 1 of this series, I now need to move to the next step - setting up my chromebook with Linux in order to facilitate node.js development. I chose a chromebook as my dev machine of choice as I wanted something that natively runs on Linux, but didn\u0026rsquo;t want to pay as much as a Mac and didn\u0026rsquo;t really like the Linux based machine options out there\u0026hellip; Google is doing a great job with these and after having my chromebook for a little over a week - I have to say I love it\u0026hellip;","tags":null,"title":"My Path to node.js and Oracle Glory - Volume 2"},{"categories":null,"contents":"I am starting a new personal project with the following goals in mind:\n Learn JavaScript (I\u0026rsquo;m a beginner, but been reading/implementing for a while) Learn node.js Create a RESTful API using node.js calling a remote database server using Oracle\u0026rsquo;s node driver (node-oracledb)   API should be simple to understand API in the backend should use the HR sample schema When using node.js, goal is to form a service request object in javascript and pass that object to a stored procedure in Oracle as an IN parameter, the same stored procedure should return a response object that will be parsed in javascript and the results displayed   DISCLAIMER - When I actually have free time to develop - I am primarily a PL/SQL developer \u0026ndash; I love PL/SQL - there I said it! I work with java and perl, but at the end of the day, I love the insulated, hassle-free world of developing within a database. I know enough of command line to get by, but my 4th major goal is to become a command line \u0026ldquo;expert\u0026rdquo; (or at least know where all the relevant references I need are) for sqlplus and more importantly Linux, so bear with me as I toil through the basics along the way!\n So, on to the actual work - I am going to setup two machines on my home network \u0026ndash; one machine (an old Windows 7 laptop) will act as a database server, the other machine (my new Chromebook) will act as the calling application (in this case node.js using Oracle\u0026rsquo;s node-Oracledb driver).\nStep 1. Install Oracle XE on my windows machine using this URL - I won\u0026rsquo;t go into depth on how to install XE as it\u0026rsquo;s well documented.\nStep 2. DO NOT DO THIS! Live and learn - I had no idea that the HR and other sample schemas are already installed with XE and went through all the below steps to clone and install the schema, only to figure out that I had accidentally installed the HR objects in the SYSTEM schema (I\u0026rsquo;ve now corrected the steps)\u0026hellip;. Anyway, if for some reason, you need to install Oracle\u0026rsquo;s sample schemas in your XE instance using Christopher Jones\u0026rsquo; db-sample-schemas on Github at this URL, then follow these steps!\n  If you\u0026rsquo;re not familiar with Github, it\u0026rsquo;s definitely worth your while to learn about it, though there is a learning curve (I still suck at it, actually, but getting there\u0026hellip;)\n  Install Github for Windows using this URL\n  Once installed, you can just go to https://github.com/oracle/db-sample-schemas.git and choose \u0026ldquo;Clone in Desktop\u0026rdquo; and choose the folder location you wish to store the db-sample-schemas repository. If you\u0026rsquo;re not comfortable with Github yet - you can always get the same files by choosing \u0026ldquo;Download ZIP\u0026rdquo;\n  After you\u0026rsquo;ve cloned or downloaded the files, navigate to the human_resources directory using the Windows command line interface (cmd.exe).\n  When you\u0026rsquo;re in the directory, type sqlplus - you\u0026rsquo;ll then be asked to login - be sure to login as the HR schema. I am assuming you\u0026rsquo;ve already created the HR schema. If you have not, you should - you\u0026rsquo;ll need to figure that out on your own though. You can look at the hr_main.sql in the human_resources directory that you just downloaded for an example of creating HR.\n  After you\u0026rsquo;re logged in as HR in sqlplus, just type @hr_cre.sql - sqlplus will then execute the script and create all the necessary objects. You can then type @hr_popul.sql to populate the tables you just created with data!\n  Anyway, if you screw things up like I did, Christopher has nicely provided a script hr_drop.sql that you can run whenever necessary.\n  Step 3. Open up Windows firewall for Port 1521:\n  To enable remote calls from my Chromebook, I need to enable Firewall rules on my Windows machine so that data can flow in and out of the machine through port 1521 (the standard port that Oracle is configured for)\n  First, you want to be sure your listener is up and running for the Oracle XE instance you installed (it should be by default), but you can check in the Windows command line interface (cmd.exe) by typing lsnrctl status (you don\u0026rsquo;t have to browse anywhere in particular for this command)\n  You can find out some critical items from this status, ie your HOST and PORT (will be 1521 by default) which you\u0026rsquo;ll need when connecting later\n  Click here for more information on Managing Network Connections - doc shows you how to stop and start your db listener if you need me to\u0026hellip;\n    Assuming you are using the default port, next step is to open up connections (inbound and outbound) on it\n Goto Start -\u0026gt; Control Panel -\u0026gt; System and Security -\u0026gt; Windows Firewall -\u0026gt; Advanced settings  Once in Advanced Settings, you\u0026rsquo;ll see a window titled \u0026ldquo;Windows Firewall with Advanced Security\u0026rdquo; click on Inbound Rules and choose the \u0026ldquo;New Rule\u0026hellip;\u0026rdquo; action Choose \u0026ldquo;Port\u0026rdquo; when asked What type of rule would you like to create? Choose TCP when asked Does this apply to TCP or UDP? Add 1521 next to Specified Local Ports Choose Allow the connection Rule applies to whichever domain you choose\u0026hellip; Give the rule a name - I chose OracleInboundPort, click Finish Rinse and repeat the above for the Outbound Rules, just name the rule appropriately, i.e. OracleOutboundPort      That\u0026rsquo;s it for today - next up Volume 2, Configuring Linux on my Chromebook ","date":"March 9, 2015","hero":"/images/default-hero.jpg","permalink":"https://gilcrest.github.io/posts/archive/node-oracle-glory/volume-1/","summary":"I am starting a new personal project with the following goals in mind:\n Learn JavaScript (I\u0026rsquo;m a beginner, but been reading/implementing for a while) Learn node.js Create a RESTful API using node.js calling a remote database server using Oracle\u0026rsquo;s node driver (node-oracledb)   API should be simple to understand API in the backend should use the HR sample schema When using node.js, goal is to form a service request object in javascript and pass that object to a stored procedure in Oracle as an IN parameter, the same stored procedure should return a response object that will be parsed in javascript and the results displayed   DISCLAIMER - When I actually have free time to develop - I am primarily a PL/SQL developer \u0026ndash; I love PL/SQL - there I said it!","tags":null,"title":"My Path to node.js and Oracle Glory - Volume 1"},{"categories":null,"contents":"I recently ran into an issue where, as part of a webservice call I was making using the Oracle APEX_WEB_SERVICE API, I needed to pass the application id and password in the soap header, but I did not want those sensitive data elements to be exposed in my pl/sql code in cleartext. I decided I wanted to encrypt the data and retrieve it at run time as a function call. I tried to find a way to do this via Stack Overflow, Google, etc. but was unable to find a very simple way to do this\u0026hellip;.\nI found many great posts on how to do encryption, but I was looking for a dead easy way to encrypt and persist random pieces of data and be able to retrieve it when necessary just as easily\u0026hellip; I decided to build the solution myself! I have put a project up on GitHub, that I named Name:Value Encryption or NVE. You can find the code on Github at https://github.com/gilcrest/nve\nThis is definitely v1 of the code and I\u0026rsquo;d love for the community to participate and give me pull requests to improve this! My first mistake may be calling this Name:Value instead of Key:Value - not sure which is more accepted at this point\u0026hellip;\n","date":"December 17, 2014","hero":"/images/default-hero.jpg","permalink":"https://gilcrest.github.io/posts/archive/name-value-encryption/","summary":"I recently ran into an issue where, as part of a webservice call I was making using the Oracle APEX_WEB_SERVICE API, I needed to pass the application id and password in the soap header, but I did not want those sensitive data elements to be exposed in my pl/sql code in cleartext. I decided I wanted to encrypt the data and retrieve it at run time as a function call. I tried to find a way to do this via Stack Overflow, Google, etc.","tags":null,"title":"Name:Value Encryption Utility using PL/SQL"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://gilcrest.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"}]